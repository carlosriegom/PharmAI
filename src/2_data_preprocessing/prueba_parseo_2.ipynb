{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parseo de los txt**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from typing import Union\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las expresiones regulares para cada sección\n",
    "regex_secciones = {\n",
    "    \"indicaciones\": r'^4\\.1\\.?\\s*Indicaciones\\s+terapéuticas',\n",
    "    \"posologia\": r'^4\\.2\\.?\\s*Posolog[ií]a\\s+y\\s+forma\\s+de\\s+administraci[oó]n',\n",
    "    \"contraindicaciones\": r'^4\\.3\\.?\\s*Contraindicaciones',\n",
    "    \"advertencias\": r'^4\\.4\\.?\\s*Advertencias\\s+y\\s+precauciones\\s+especiales\\s+de\\s+empleo',\n",
    "    \"interacciones\": r'^4\\.5\\.?\\s*Interacci[oó]n\\s+con\\s+otros\\s+medicamentos',\n",
    "    \"fertilidad_embarazo\": r'^4\\.6\\.?\\s*Fertilidad,\\s+embarazo\\s+y\\s+lactancia',\n",
    "    \"efectos_conducir\": r'^4\\.7\\.?\\s*Efectos\\s+sobre\\s+la\\s+capacidad\\s+para\\s+conducir',\n",
    "    \"reacciones_adversas\": r'^4\\.8\\.?\\s*Reacciones\\s+adversas',\n",
    "    \"sobredosis\": r'^4\\.9\\.?\\s*Sobredosis',\n",
    "    \"ATC\": r'^5\\.1\\.?\\s*Propiedades\\s+farmacodin[aá]micas',\n",
    "    \"Propiedades_farmacocineticas\": r'^5\\.2\\.?\\s*Propiedades\\s+farmacocin[eé]ticas',\n",
    "    \"excipientes\": r'^6\\.1\\.?\\s*Lista\\s+de\\s+excipientes',\n",
    "    \"incompatibilidades\": r'^6\\.2\\.?\\s*Incompatibilidades',\n",
    "    \"precauciones_conservacion\": r'^6\\.4\\.?\\s*Precauciones\\s+especiales\\s+de\\s+conservaci[oó]n',\n",
    "    \"fecha_revision\": r'^10\\.\\s*FECHA\\s+DE\\s+LA\\s+REVISI[OÓ]N\\s+DEL\\s+TEXTO'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_fecha_revision(data: dict) -> dict:\n",
    "    \"\"\"Elimina el texto específico y sustituye saltos de línea por espacios en la sección fecha_revision\"\"\"\n",
    "    if 'fecha_revision' in data and data['fecha_revision']:\n",
    "        # Texto a eliminar con posibles saltos de línea\n",
    "        patron = re.compile(\n",
    "            r'(\\s*La información detallada y actualizada de este medicamento está disponible en la página Web de la\\s*'\n",
    "            r'Agencia Española de Medicamentos y Productos Sanitarios \\(AEMPS\\) http://www\\.aemps\\.gob\\.es/\\s*)',\n",
    "            re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        \n",
    "        # Sustituir saltos de línea por espacios solo en el texto a eliminar\n",
    "        def reemplazar_saltos(match):\n",
    "            return ' '\n",
    "        \n",
    "        data['fecha_revision'] = patron.sub(reemplazar_saltos, data['fecha_revision']).strip()\n",
    "        \n",
    "        # Eliminar espacios múltiples resultantes\n",
    "        data['fecha_revision'] = re.sub(r'\\s+', ' ', data['fecha_revision'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_diccionario(data: dict) -> dict:\n",
    "    \"\"\"Aplica todas las técnicas de limpieza al diccionario de datos\"\"\"\n",
    "    \n",
    "    # 1. Limpieza específica de fecha_revision\n",
    "    def limpiar_fecha_revision(data: dict) -> dict:\n",
    "        if 'fecha_revision' in data and data['fecha_revision']:\n",
    "            patron = re.compile(\n",
    "                r'(\\s*La información detallada y actualizada de este medicamento está disponible en la página Web de la\\s*'\n",
    "                r'Agencia Española de Medicamentos y Productos Sanitarios \\(AEMPS\\) http://www\\.aemps\\.gob\\.es/\\s*)',\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            data['fecha_revision'] = patron.sub(' ', data['fecha_revision']).strip()\n",
    "        return data\n",
    "    \n",
    "    # 2. Sustituir saltos de línea por espacios en todas las secciones\n",
    "    def limpiar_saltos_linea(texto: str) -> str:\n",
    "        if texto:\n",
    "            # Reemplazar múltiples saltos de línea por un espacio único\n",
    "            texto = re.sub(r'[\\n\\r]+', ' ', texto)\n",
    "        return texto\n",
    "    \n",
    "    # 3. Eliminar caracteres especiales no estándar\n",
    "    def limpiar_caracteres_extraños(texto: str) -> str:\n",
    "        if texto:\n",
    "            # Eliminar caracteres especiales específicos usando sus códigos Unicode\n",
    "            texto = re.sub(r'[\\uF0B7\\uF06D]', ' ', texto)  #  (U+F0B7) y  (U+F06D)\n",
    "            \n",
    "            # También puedes incluir otros caracteres no deseados\n",
    "            texto = re.sub(r'[•▪▫►◄●]', ' ', texto)  # Bullets comunes\n",
    "            \n",
    "            # Normalizar espacios\n",
    "            texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "        return texto\n",
    "    \n",
    "    # 4. Limpiar numeraciones tipo \"X de Y\"\n",
    "    def limpiar_numeraciones(texto: str) -> str:\n",
    "        if texto:\n",
    "            # Eliminar patrones de paginación\n",
    "            texto = re.sub(r'\\b\\d+\\s+de\\s+\\d+\\b', '', texto)\n",
    "            # Normalizar espacios múltiples\n",
    "            texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "        return texto\n",
    "    \n",
    "    # Aplicar limpieza en cascada\n",
    "    data = limpiar_fecha_revision(data)\n",
    "    \n",
    "    # Procesar todas las secciones\n",
    "    for seccion, contenido in data.items():\n",
    "        if isinstance(contenido, str):\n",
    "            # Orden de transformaciones\n",
    "            contenido = limpiar_saltos_linea(contenido)\n",
    "            contenido = limpiar_caracteres_extraños(contenido)\n",
    "            contenido = limpiar_numeraciones(contenido)\n",
    "            data[seccion] = contenido\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_secciones(file_path: str) -> dict:\n",
    "    \"\"\"Extrae las secciones relevantes de un archivo TXT excluyendo los títulos\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error leyendo archivo: {str(e)}\")\n",
    "\n",
    "    current_section = None\n",
    "    data = {key: [] for key in regex_secciones.keys()}\n",
    "    control_flags = {\n",
    "        'stop_until_5_1': False,\n",
    "        'ignore_until_6_1': False,\n",
    "        'ignore_until_6_4': False,\n",
    "        'ignore_until_10': False  # Bandera para 6.5 -> 10\n",
    "    }\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Manejo de flags de control\n",
    "        if control_flags['stop_until_5_1']:\n",
    "            if re.match(r'^5\\.1\\.?\\s*Propiedades\\s+farmacodin[aá]micas', line, re.IGNORECASE):\n",
    "                control_flags['stop_until_5_1'] = False\n",
    "            continue\n",
    "        \n",
    "        if control_flags['ignore_until_6_1']:\n",
    "            if re.match(r'^6\\.1\\.?\\s*Lista\\s+de\\s+excipientes', line, re.IGNORECASE):\n",
    "                control_flags['ignore_until_6_1'] = False\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if control_flags['ignore_until_6_4']:\n",
    "            if re.match(r'^6\\.4\\.?\\s*Precauciones\\s+especiales\\s+de\\s+conservaci[oó]n', line, re.IGNORECASE):\n",
    "                control_flags['ignore_until_6_4'] = False\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        if control_flags['ignore_until_10']:\n",
    "            if re.match(r'^10\\.\\s*FECHA\\s+DE\\s+LA\\s+REVISI[OÓ]N\\s+DEL\\s+TEXTO', line, re.IGNORECASE):\n",
    "                control_flags['ignore_until_10'] = False\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Detectar sección 6.5 y activar bandera\n",
    "        if re.match(r'^6\\.5\\.?\\s*NATURALEZA\\s+Y\\s+CONTENIDO\\s+DEL\\s+ENVASE', line, re.IGNORECASE):\n",
    "            control_flags['ignore_until_10'] = True\n",
    "            current_section = None\n",
    "            continue\n",
    "\n",
    "        # Detección de secciones principales\n",
    "        section_found = False\n",
    "        for section, pattern in regex_secciones.items():\n",
    "            if re.match(pattern, line, re.IGNORECASE):\n",
    "                current_section = section\n",
    "                section_found = True\n",
    "                \n",
    "                # Manejo de flags especiales\n",
    "                if section == \"sobredosis\":\n",
    "                    control_flags['stop_until_5_1'] = True\n",
    "                elif section == \"excipientes\":\n",
    "                    control_flags['ignore_until_6_1'] = False\n",
    "                elif section == \"fecha_revision\":\n",
    "                    control_flags['ignore_until_10'] = False\n",
    "                break\n",
    "        \n",
    "        if section_found:\n",
    "            continue\n",
    "\n",
    "        # Captura de contenido solo si no hay banderas activas\n",
    "        if current_section and not any(control_flags.values()):\n",
    "            if current_section == \"ATC\":\n",
    "                if \"ATC:\" in line:\n",
    "                    if match := re.search(r'ATC:\\s*([A-Z0-9]+)', line):\n",
    "                        data[\"ATC\"] = [match.group(1)]\n",
    "                        current_section = None\n",
    "            else:\n",
    "                data[current_section].append(line)\n",
    "\n",
    "    # Limpiar y formatear datos\n",
    "    for key in data:\n",
    "        if isinstance(data[key], list):\n",
    "            data[key] = '\\n'.join(data[key]).strip()\n",
    "    \n",
    "    # Aplicar limpieza específica para la sección fecha_revision\n",
    "    data = limpiar_diccionario(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para guardar los datos en un archivo JSON\n",
    "def guardar_json(data: dict, output_path: str) -> None:\n",
    "    \"\"\"Guarda los datos en un archivo JSON en la ruta especificada\"\"\"\n",
    "    try:\n",
    "        # Crear directorios si no existen\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error guardando JSON: {str(e)}\")\n",
    "\n",
    "# Función principal para procesar archivos\n",
    "def procesar_archivos(input_path: str, output_path: str) -> dict:\n",
    "    \"\"\"Procesa un archivo o carpeta y genera los JSON correspondientes\"\"\"\n",
    "    resultados = {}\n",
    "    total_procesados = 0\n",
    "    errores = []\n",
    "\n",
    "    try:\n",
    "        if os.path.isfile(input_path):\n",
    "            if input_path.lower().endswith('.txt'):\n",
    "                data = extract_secciones(input_path)\n",
    "                guardar_json(data, output_path)\n",
    "                total_procesados += 1\n",
    "                resultados[os.path.basename(input_path)] = \"OK\"\n",
    "            else:\n",
    "                raise ValueError(\"El archivo no es un TXT\")\n",
    "        \n",
    "        elif os.path.isdir(input_path):\n",
    "            json_final = {}\n",
    "            for filename in os.listdir(input_path):\n",
    "                if filename.lower().endswith('.txt'):\n",
    "                    file_path = os.path.join(input_path, filename)\n",
    "                    try:\n",
    "                        data = extract_secciones(file_path)\n",
    "                        json_final[filename] = data\n",
    "                        total_procesados += 1\n",
    "                    except Exception as e:\n",
    "                        errores.append(filename)\n",
    "                        resultados[filename] = f\"Error: {str(e)}\"\n",
    "            \n",
    "            guardar_json(json_final, output_path)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"La ruta no es válida\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        resultados[\"error\"] = f\"Error general: {str(e)}\"\n",
    "    \n",
    "    # Mostrar resumen\n",
    "    print(f\"\\nProceso completado. Archivos procesados: {total_procesados}\")\n",
    "    if errores:\n",
    "        print(f\"\\nArchivos con errores ({len(errores)}):\")\n",
    "        for error in errores:\n",
    "            print(f\"- {error}\")\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando procesamiento de: ../../data/inputs/1_data_acquisition/wrangler/A.A.S._100_mg_COMPRIMIDOS.txt\n",
      "\n",
      "Proceso completado. Archivos procesados: 1\n",
      "\n",
      "Ejecución completada\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el script\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Configuración manual\n",
    "    input_path = os.path.join(\"..\", \"..\", \"data\", \"inputs\", \"1_data_acquisition\", \"wrangler\", \"A.A.S._100_mg_COMPRIMIDOS.txt\")  \n",
    "    nombre_archivo_txt = os.path.basename(input_path).replace(\".txt\", \"\")\n",
    "    output_path = os.path.join(\"..\", \"..\", \"data\", \"outputs\", \"1_data_acquisition\", \"wrangler\", f\"{nombre_archivo_txt}.json\")  \n",
    "    \n",
    "    # Ejecutar procesamiento\n",
    "    try:\n",
    "        print(f\"\\nIniciando procesamiento de: {input_path}\")\n",
    "        resultados = procesar_archivos(input_path, output_path)\n",
    "        print(\"\\nEjecución completada\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: Fallo en el procesamiento - {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
