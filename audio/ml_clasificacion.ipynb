{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5908a7df",
   "metadata": {},
   "source": [
    "### **Problema de clasificación de audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84cb6f",
   "metadata": {},
   "source": [
    "El problema trata de clasificar un audio intentando predecir a qué clase pertenece. Las distintas clases se dividen por la intención que tenga el usuario al hacer la consulta. En nuestro caso tenemos: `efectos_adversos` y `otros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fe9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1df9b2",
   "metadata": {},
   "source": [
    "#### 1. **Generamos dataframe con audios y clases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab5b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con 20 filas y 2 columnas:\n",
      "             filename             label\n",
      "0  audio_10_angel.wav  efectos_adversos\n",
      "1   audio_1_angel.wav  efectos_adversos\n",
      "2   audio_2_angel.wav  efectos_adversos\n",
      "3   audio_3_angel.wav  efectos_adversos\n",
      "4   audio_4_angel.wav  efectos_adversos\n"
     ]
    }
   ],
   "source": [
    "# 1) Carpeta base donde están tus audios organizados por subcarpeta = etiqueta\n",
    "AUDIO_BASE = \"data/outputs/6_audio\"\n",
    "# 2) Ruta donde guardar el CSV (si quieres)\n",
    "OUT_CSV = \"data/metadata.csv\"\n",
    "\n",
    "# 3) Recorre las subcarpetas y recoge filename + label\n",
    "rows = []\n",
    "for label in os.listdir(AUDIO_BASE):\n",
    "    class_dir = os.path.join(AUDIO_BASE, label)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.lower().endswith(\".wav\"):\n",
    "                rows.append({\n",
    "                    \"filename\": fname,\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "# 4) Crea el DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"filename\", \"label\"])\n",
    "\n",
    "# 5) (Opcional) Guárdalo en CSV\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# 6) Comprueba resultado\n",
    "print(f\"DataFrame con {len(df)} filas y {len(df.columns)} columnas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a31ba",
   "metadata": {},
   "source": [
    "#### 2. **Clasificación de audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36ce5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m        \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m         \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils_audio_sin_problemas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     preprocess_audio,\n\u001b[32m     13\u001b[39m     extract_zcr,\n\u001b[32m     14\u001b[39m     extract_centroid_rolloff,\n\u001b[32m     15\u001b[39m     extract_mfcc\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 1) Cargamos el DataFrame\u001b[39;00m\n\u001b[32m     19\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\MBD_ICAI_repo\\MBD_ICAI\\Analisis_de_Datos_No_Estructurados_ADNoE\\PharmAI\\audio\\utils_audio_sin_problemas.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwhisper\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\PharmAI3\\Lib\\site-packages\\whisper.py:69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CAN_FALLOCATE:\n\u001b[32m     68\u001b[39m   libc_name = ctypes.util.find_library(\u001b[33m'\u001b[39m\u001b[33mc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m   libc = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibc_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m   c_off64_t = ctypes.c_int64\n\u001b[32m     71\u001b[39m   c_off_t = ctypes.c_int\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\PharmAI3\\Lib\\ctypes\\__init__.py:366\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnt\u001b[39;00m\n\u001b[32m    365\u001b[39m mode = nt._LOAD_LIBRARY_SEARCH_DEFAULT_DIRS\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m._name = nt._getfullpathname(\u001b[38;5;28mself\u001b[39m._name)\n\u001b[32m    368\u001b[39m     mode |= nt._LOAD_LIBRARY_SEARCH_DLL_LOAD_DIR\n",
      "\u001b[31mTypeError\u001b[39m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.metrics         import classification_report, confusion_matrix\n",
    "\n",
    "from utils_audio import (\n",
    "    preprocess_audio,\n",
    "    extract_zcr,\n",
    "    extract_centroid_rolloff,\n",
    "    extract_mfcc\n",
    ")\n",
    "\n",
    "# 1) Cargamos el DataFrame\n",
    "df = pd.read_csv(\"data/metadata.csv\")\n",
    "AUDIO_BASE = \"data/outputs/6_audio\"\n",
    "\n",
    "# 2) Función para vectorizar un clip (igual que antes)\n",
    "def extract_clip_features(label: str, fname: str):\n",
    "    clip_path = os.path.join(AUDIO_BASE, label, fname)\n",
    "    y = preprocess_audio(clip_path, reduce_noise_flag=False)\n",
    "    if y is None:\n",
    "        print(f\"Skipping (preproc failure): {clip_path}\")\n",
    "        return None\n",
    "\n",
    "    zcr        = extract_zcr(y, sr=16000)                   \n",
    "    centroid, rolloff = extract_centroid_rolloff(y, sr=16000)  \n",
    "    mfcc       = extract_mfcc(y, sr=16000, n_mfcc=13)        \n",
    "\n",
    "    feats = []\n",
    "    for arr in (zcr, centroid, rolloff):\n",
    "        feats += [arr.mean(), arr.std()]\n",
    "    feats += list(mfcc.mean(axis=1)) + list(mfcc.std(axis=1))\n",
    "\n",
    "    return np.array(feats)\n",
    "\n",
    "# 3) Recorremos df para llenar X_list, y_list\n",
    "X_list, y_list = [], []\n",
    "for _, row in df.iterrows():\n",
    "    feats = extract_clip_features(row['label'], row['filename'])\n",
    "    if feats is not None:\n",
    "        X_list.append(feats)\n",
    "        y_list.append(row['label'])\n",
    "\n",
    "# Ahora sí construimos X e y\n",
    "X = np.vstack(X_list)      # (n_clips, n_features)\n",
    "y = np.array(y_list)       # (n_clips,)\n",
    "\n",
    "# 4) Split, pipeline, entrenamiento…\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [100, 200],\n",
    "    \"clf__max_depth\":    [None, 10, 20],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmAI3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
