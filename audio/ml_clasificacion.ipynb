{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5908a7df",
   "metadata": {},
   "source": [
    "### **Problema de clasificación de audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84cb6f",
   "metadata": {},
   "source": [
    "El problema trata de clasificar un audio intentando predecir a qué clase pertenece. Las distintas clases se dividen por la intención que tenga el usuario al hacer la consulta. En nuestro caso tenemos: `efectos_adversos` y `otros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.metrics         import classification_report, confusion_matrix\n",
    "\n",
    "from utils_audio import (\n",
    "    preprocess_audio,\n",
    "    extract_zcr,\n",
    "    extract_centroid_rolloff,\n",
    "    extract_mfcc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1df9b2",
   "metadata": {},
   "source": [
    "#### 1. **Generamos dataframe con audios y clases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab5b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con 20 filas y 2 columnas:\n",
      "             filename             label\n",
      "0  audio_10_angel.wav  efectos_adversos\n",
      "1   audio_1_angel.wav  efectos_adversos\n",
      "2   audio_2_angel.wav  efectos_adversos\n",
      "3   audio_3_angel.wav  efectos_adversos\n",
      "4   audio_4_angel.wav  efectos_adversos\n"
     ]
    }
   ],
   "source": [
    "# 1) Carpeta base donde están tus audios organizados por subcarpeta = etiqueta\n",
    "AUDIO_BASE = \"data/outputs/6_audio\"\n",
    "# 2) Ruta donde guardar el CSV (si quieres)\n",
    "OUT_CSV = \"data/metadata.csv\"\n",
    "\n",
    "# 3) Recorre las subcarpetas y recoge filename + label\n",
    "rows = []\n",
    "for label in os.listdir(AUDIO_BASE):\n",
    "    class_dir = os.path.join(AUDIO_BASE, label)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.lower().endswith(\".wav\"):\n",
    "                rows.append({\n",
    "                    \"filename\": fname,\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "# 4) Crea el DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"filename\", \"label\"])\n",
    "\n",
    "# 5) (Opcional) Guárdalo en CSV\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# 6) Comprueba resultado\n",
    "print(f\"DataFrame con {len(df)} filas y {len(df.columns)} columnas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a31ba",
   "metadata": {},
   "source": [
    "#### 2. **Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deed535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cargamos el DataFrame\n",
    "df = pd.read_csv(\"data/metadata.csv\")\n",
    "AUDIO_BASE = \"data/outputs/6_audio\"\n",
    "\n",
    "# 2) Función para vectorizar un clip (igual que antes)\n",
    "def extract_clip_features(label: str, fname: str):\n",
    "    clip_path = os.path.join(AUDIO_BASE, label, fname)\n",
    "    y = preprocess_audio(clip_path, reduce_noise_flag=False)\n",
    "    if y is None:\n",
    "        print(f\"Skipping (preproc failure): {clip_path}\")\n",
    "        return None\n",
    "\n",
    "    zcr        = extract_zcr(y, sr=16000)                   \n",
    "    centroid, rolloff = extract_centroid_rolloff(y, sr=16000)  \n",
    "    mfcc       = extract_mfcc(y, sr=16000, n_mfcc=13)        \n",
    "\n",
    "    feats = []\n",
    "    for arr in (zcr, centroid, rolloff):\n",
    "        feats += [arr.mean(), arr.std()]\n",
    "    feats += list(mfcc.mean(axis=1)) + list(mfcc.std(axis=1))\n",
    "\n",
    "    return np.array(feats)\n",
    "\n",
    "# 3) Recorremos df para llenar X_list, y_list\n",
    "X_list, y_list = [], []\n",
    "for _, row in df.iterrows():\n",
    "    feats = extract_clip_features(row['label'], row['filename'])\n",
    "    if feats is not None:\n",
    "        X_list.append(feats)\n",
    "        y_list.append(row['label'])\n",
    "\n",
    "# Ahora sí construimos X e y\n",
    "X = np.vstack(X_list)      # (n_clips, n_features)\n",
    "y = np.array(y_list)       # (n_clips,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36ce5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m        \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m         \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils_audio_sin_problemas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     preprocess_audio,\n\u001b[32m     13\u001b[39m     extract_zcr,\n\u001b[32m     14\u001b[39m     extract_centroid_rolloff,\n\u001b[32m     15\u001b[39m     extract_mfcc\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 1) Cargamos el DataFrame\u001b[39;00m\n\u001b[32m     19\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\MBD_ICAI_repo\\MBD_ICAI\\Analisis_de_Datos_No_Estructurados_ADNoE\\PharmAI\\audio\\utils_audio_sin_problemas.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwhisper\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\PharmAI3\\Lib\\site-packages\\whisper.py:69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CAN_FALLOCATE:\n\u001b[32m     68\u001b[39m   libc_name = ctypes.util.find_library(\u001b[33m'\u001b[39m\u001b[33mc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m   libc = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibc_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m   c_off64_t = ctypes.c_int64\n\u001b[32m     71\u001b[39m   c_off_t = ctypes.c_int\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\anaconda3\\envs\\PharmAI3\\Lib\\ctypes\\__init__.py:366\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnt\u001b[39;00m\n\u001b[32m    365\u001b[39m mode = nt._LOAD_LIBRARY_SEARCH_DEFAULT_DIRS\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m._name = nt._getfullpathname(\u001b[38;5;28mself\u001b[39m._name)\n\u001b[32m    368\u001b[39m     mode |= nt._LOAD_LIBRARY_SEARCH_DLL_LOAD_DIR\n",
      "\u001b[31mTypeError\u001b[39m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "# 4) Split, pipeline, entrenamiento…\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [100, 200],\n",
    "    \"clf__max_depth\":    [None, 10, 20],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f63268",
   "metadata": {},
   "source": [
    "##### **Evaluación del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97901d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m     plt.show()\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Ejemplo de uso (descomenta y ajusta):\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m y_test_series = pd.Series(\u001b[43my_test\u001b[49m, name=\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     89\u001b[39m probas = grid.best_estimator_.predict_proba(X_test)\n\u001b[32m     90\u001b[39m plotClassPerformance(y_test_series, probas, selClass=\u001b[33m\"\u001b[39m\u001b[33mefectos_adversos\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def plotClassPerformance(y: pd.Series,\n",
    "                         prob_est: np.ndarray,\n",
    "                         selClass: str = None,\n",
    "                         figsize: tuple = (10, 5)):\n",
    "    \"\"\"\n",
    "    Crea 4 gráficas de rendimiento de clasificación para un problema binario:\n",
    "      1) Calibration plot\n",
    "      2) Histograma de probabilidades\n",
    "      3) ROC Curve con AUC\n",
    "      4) Accuracy vs umbral\n",
    "\n",
    "    Args:\n",
    "        y (pd.Series): valores verdaderos, dtype categórico o object.\n",
    "        prob_est (np.ndarray): array (n_samples, 2) de probabilidades predichas.\n",
    "        selClass (str, opcional): clase positiva. Si None, toma la segunda categoría.\n",
    "        figsize (tuple): tamaño de las figuras.\n",
    "    \"\"\"\n",
    "    # Determinar categorías\n",
    "    try:\n",
    "        categories = y.cat.categories\n",
    "    except AttributeError:\n",
    "        categories = np.unique(y)\n",
    "    # Seleccionar clase positiva\n",
    "    if selClass is None:\n",
    "        selClass = categories[1] if len(categories) > 1 else categories[0]\n",
    "        warnings.warn(f'Usando \"{selClass}\" como clase positiva', UserWarning)\n",
    "    # Índice de la clase positiva\n",
    "    pos_idx = list(categories).index(selClass)\n",
    "\n",
    "    # Binarizar y extraer score\n",
    "    y_true = (y == selClass).astype(int)\n",
    "    scores = prob_est[:, pos_idx]\n",
    "\n",
    "    # 1) Calibration plot\n",
    "    frac_pos, mean_pred = calibration_curve(y_true, scores, n_bins=10)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(mean_pred, frac_pos, marker='o', linewidth=1, label='Modelo')\n",
    "    line = mlines.Line2D([0, 1], [0, 1], color='black', transform=ax.transAxes)\n",
    "    ax.add_line(line)\n",
    "    ax.set_title('Plot 1/4: Calibration Plot')\n",
    "    ax.set_xlabel('Probabilidad Predicha')\n",
    "    ax.set_ylabel('Fracción Verdadera')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Histograma de probabilidades\n",
    "    df = pd.DataFrame({'y': y, 'score': scores})\n",
    "    g = sns.FacetGrid(df, col='y', sharex=True, height=figsize[1], aspect=figsize[0]/(2*figsize[1]))\n",
    "    bins = np.linspace(0, 1, 10)\n",
    "    g.map(plt.hist, 'score', bins=bins)\n",
    "    g.fig.suptitle(f'Plot 2/4: Distribución de Probabilidades para \"{selClass}\"', y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    ax.set_title('Plot 3/4: ROC Curve')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 4) Accuracy vs Threshold\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    accuracies = [accuracy_score(y_true, (scores >= t).astype(int)) for t in thresholds]\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(thresholds, accuracies)\n",
    "    ax.set_title('Plot 4/4: Accuracy vs Threshold')\n",
    "    ax.set_xlabel('Umbral de Probabilidad')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso (descomenta y ajusta):\n",
    "y_test_series = pd.Series(y_test, name=\"label\")\n",
    "probas = grid.best_estimator_.predict_proba(X_test)\n",
    "plotClassPerformance(y_test_series, probas, selClass=\"efectos_adversos\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmAI3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
